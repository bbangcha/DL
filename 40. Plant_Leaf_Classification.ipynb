{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1X9A1QNyPrm3QnxLP_17VNoX36h63US_A","authorship_tag":"ABX9TyO6MH9wD7cveYuPEApoJADo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6-LvoY4_r-SH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707295562279,"user_tz":-540,"elapsed":2157,"user":{"displayName":"이병찬","userId":"10612252081270695585"}},"outputId":"239c9aff-d4d3-4b5f-a335-a361817884b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!unzip -qq '/content/drive/MyDrive/제로베이스_코랩/dataset.zip' -d '/content/drive/MyDrive/제로베이스_코랩/dataset'\n","# -d : 압축파일을 푸는 경로를 지정하는 옵션"],"metadata":{"id":"xHa3gQCVtszy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","original_dataset_dir = '/content/drive/MyDrive/제로베이스_코랩/dataset'\n","classes_list = os.listdir(original_dataset_dir)\n","\n","base_dir = '/content/drive/MyDrive/제로베이스_코랩/splitted'\n","os.mkdir(base_dir)"],"metadata":{"id":"N0-6toqBts2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 정리를 위한 목록 및 폴더 생성\n","- 하기의 폴더들은 모두 base_dir의 splitted 폴더 안에 생성"],"metadata":{"id":"zDmzDXzmgJPE"}},{"cell_type":"code","source":["import shutil\n","\n","# train, validation, test의 directory 만들기\n","train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","\n","validation_dir = os.path.join(base_dir, 'val')\n","os.mkdir(validation_dir)\n","\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)\n","\n","# classes_list : 폴더의 목록이 있는 리스트\n","# for문을 통해 train, validation, test의 directory 안에 classes_list 동일 폴더 만들기\n","for cls in classes_list:\n","  os.mkdir(os.path.join(train_dir, cls))\n","  os.mkdir(os.path.join(validation_dir, cls))\n","  os.mkdir(os.path.join(test_dir, cls))"],"metadata":{"id":"oatz9u9-ts4V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 현황 확인"],"metadata":{"id":"Ub4X9yi9gFWR"}},{"cell_type":"code","source":["import math\n","\n","# classes_list의 cls(폴더명)이 하나씩 돌면서 join된 original_dataset_dir인 dataset의 파일이 fnames에 하나씩 담긴다\n","# ex) dataset 중 classes_list의 cls인 Apple__Apple_scab가 path에 담기고\n","# path에 의해 Apple__Apple_scab의 파일인 image(107), image(108).. 등이 fnames에 담긴다\n","for cls in classes_list:\n","  path = os.path.join(original_dataset_dir, cls)\n","  fnames = os.listdir(path)\n","\n","  # train, validation, test 데이터 나누기 (6:2:2)\n","  train_size = math.floor(len(fnames) * 0.6)\n","  validation_size = math.floor(len(fnames) * 0.2)\n","  test_size = math.floor(len(fnames) * 0.2)\n","\n","  train_fnames = fnames[:train_size]\n","  print('Train size(\",cls,\"):', len(train_fnames))\n","  for fname in train_fnames:\n","    scr = os.path.join(path, fname)\n","    dst = os.path.join(os.path.join(train_dir, cls), fname)\n","    shutil.copyfile(scr, dst) # 복사를 위한 코드\n","\n","  validation_fnames = fnames[train_size:(validation_size + train_size)]\n","  print('Validation size(\",cls,\"):', len(validation_fnames))\n","  for fname in validation_fnames:\n","    src = os.path.join(path, fname)\n","    dst = os.path.join(os.path.join(validation_dir, cls), fname)\n","    shutil.copyfile(scr, dst)\n","\n","  test_fnames = fnames[(validation_size + train_size):(validation_size + train_size + test_size)]\n","  print('Test size(\",cls,\"):', len(test_fnames))\n","  for fname in test_fnames:\n","    src = os.path.join(path, fname)\n","    dst = os.path.join(os.path.join(test_dir, cls), fname)\n","    shutil.copyfile(scr, dst)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kk327be3ts6c","executionInfo":{"status":"ok","timestamp":1707201219185,"user_tz":-540,"elapsed":636096,"user":{"displayName":"이병찬","userId":"10612252081270695585"}},"outputId":"651d729c-85c5-4e31-89b0-bb2127e004db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train size(\",cls,\"): 886\n","Validation size(\",cls,\"): 295\n","Test size(\",cls,\"): 295\n","Train size(\",cls,\"): 829\n","Validation size(\",cls,\"): 276\n","Test size(\",cls,\"): 276\n","Train size(\",cls,\"): 598\n","Validation size(\",cls,\"): 199\n","Test size(\",cls,\"): 199\n","Train size(\",cls,\"): 273\n","Validation size(\",cls,\"): 91\n","Test size(\",cls,\"): 91\n","Train size(\",cls,\"): 708\n","Validation size(\",cls,\"): 236\n","Test size(\",cls,\"): 236\n","Train size(\",cls,\"): 715\n","Validation size(\",cls,\"): 238\n","Test size(\",cls,\"): 238\n","Train size(\",cls,\"): 378\n","Validation size(\",cls,\"): 126\n","Test size(\",cls,\"): 126\n","Train size(\",cls,\"): 91\n","Validation size(\",cls,\"): 30\n","Test size(\",cls,\"): 30\n","Train size(\",cls,\"): 600\n","Validation size(\",cls,\"): 200\n","Test size(\",cls,\"): 200\n","Train size(\",cls,\"): 512\n","Validation size(\",cls,\"): 170\n","Test size(\",cls,\"): 170\n","Train size(\",cls,\"): 1276\n","Validation size(\",cls,\"): 425\n","Test size(\",cls,\"): 425\n","Train size(\",cls,\"): 372\n","Validation size(\",cls,\"): 124\n","Test size(\",cls,\"): 124\n","Train size(\",cls,\"): 631\n","Validation size(\",cls,\"): 210\n","Test size(\",cls,\"): 210\n","Train size(\",cls,\"): 307\n","Validation size(\",cls,\"): 102\n","Test size(\",cls,\"): 102\n","Train size(\",cls,\"): 216\n","Validation size(\",cls,\"): 72\n","Test size(\",cls,\"): 72\n","Train size(\",cls,\"): 600\n","Validation size(\",cls,\"): 200\n","Test size(\",cls,\"): 200\n","Train size(\",cls,\"): 3214\n","Validation size(\",cls,\"): 1071\n","Test size(\",cls,\"): 1071\n","Train size(\",cls,\"): 645\n","Validation size(\",cls,\"): 215\n","Test size(\",cls,\"): 215\n","Train size(\",cls,\"): 600\n","Validation size(\",cls,\"): 200\n","Test size(\",cls,\"): 200\n","Train size(\",cls,\"): 253\n","Validation size(\",cls,\"): 84\n","Test size(\",cls,\"): 84\n","Train size(\",cls,\"): 165\n","Validation size(\",cls,\"): 55\n","Test size(\",cls,\"): 55\n","Train size(\",cls,\"): 591\n","Validation size(\",cls,\"): 197\n","Test size(\",cls,\"): 197\n","Train size(\",cls,\"): 1062\n","Validation size(\",cls,\"): 354\n","Test size(\",cls,\"): 354\n","Train size(\",cls,\"): 697\n","Validation size(\",cls,\"): 232\n","Test size(\",cls,\"): 232\n","Train size(\",cls,\"): 665\n","Validation size(\",cls,\"): 221\n","Test size(\",cls,\"): 221\n","Train size(\",cls,\"): 223\n","Validation size(\",cls,\"): 74\n","Test size(\",cls,\"): 74\n","Train size(\",cls,\"): 571\n","Validation size(\",cls,\"): 190\n","Test size(\",cls,\"): 190\n","Train size(\",cls,\"): 1145\n","Validation size(\",cls,\"): 381\n","Test size(\",cls,\"): 381\n","Train size(\",cls,\"): 954\n","Validation size(\",cls,\"): 318\n","Test size(\",cls,\"): 318\n","Train size(\",cls,\"): 1005\n","Validation size(\",cls,\"): 335\n","Test size(\",cls,\"): 335\n","Train size(\",cls,\"): 987\n","Validation size(\",cls,\"): 329\n","Test size(\",cls,\"): 329\n","Train size(\",cls,\"): 842\n","Validation size(\",cls,\"): 280\n","Test size(\",cls,\"): 280\n","Train size(\",cls,\"): 1378\n","Validation size(\",cls,\"): 459\n","Test size(\",cls,\"): 459\n"]}]},{"cell_type":"code","source":["import torch\n","import os\n","\n","USE_CODE = torch.cuda.is_available\n","DEVICE = torch.device('cuda' if USE_CODE else 'cpu')\n","BATCH_SIZE = 256\n","EPOCH = 30"],"metadata":{"id":"P_w3pj7ats8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ImageFolder : 폴더 이름을 라벨로 작업해주는 메써드"],"metadata":{"id":"f_7UjFzkj7tR"}},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","\n","transfrom_base = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n","train_dataset = ImageFolder(root='/content/drive/MyDrive/제로베이스_코랩/splitted/train', transform = transfrom_base)\n","val_dataset = ImageFolder(root='/content/drive/MyDrive/제로베이스_코랩/splitted/val', transform = transfrom_base)"],"metadata":{"id":"uCZRHBiyts-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle = True,\n","                                           num_workers = 4)\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle = True,\n","                                          num_workers = 4)"],"metadata":{"id":"n3gqyxbwttA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class Net(nn.Module):\n","\n","  def __init__(self):\n","\n","    super(Net, self).__init__()\n","\n","    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","    self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n","\n","    self.fc1 = nn.Linear(4096, 512)\n","    self.fc2 = nn.Linear(512, 33)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = self.pool(x)\n","    x = F.dropout(x, p = 0.25, training=self.training)\n","    # training=self.training : 학습할때만 학습율 사용, 테스트할 때는 미사용하겠다는 설정\n","\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = self.pool(x)\n","    x = F.dropout(x, p = 0.25, training=self.training)\n","\n","    x = self.conv3(x)\n","    x = F.relu(x)\n","    x = self.pool(x)\n","    x = F.dropout(x, p = 0.25, training=self.training)\n","\n","    x = x.view(-1, 4096) # platten()과 같은 기능\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = F.dropout(x, p = 0.25, training=self.training)\n","    x = self.fc2(x)\n","\n","    return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"678DWBmrttDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_base = Net().to(DEVICE)\n","optimizer = optim.Adam(model_base.parameters(), lr = 0.001)"],"metadata":{"id":"GHl_0nIp3MS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, opmtimizer):\n","  model.train()\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    data, target = data.to(DEVICE), target.to(DEVICE)\n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = F.cross_entropy(output, target)\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"4GOtjH_L3MVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, test_loader):\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  # with 구문은 끝나면 resorce가 저절로 닫힌다\n","  with torch.no_grad():\n","    for data, target in test_loader:\n","      data, target = data.to(DEVICE), target.to(DEVICE)\n","      output = model(data)\n","\n","      test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","\n","      pred = output.max(1, keepdim = True)[1]\n","      correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","  test_loss /= len(test_loader.dataset)\n","  # /= : 왼쪽 변수에 오른쪽 값을 나누고 그 결과를 왼쪽 변수에 할당\n","  # ex) a /= b  -> a = a/b\n","  test_accuracy = 100. * correct / len(test_loader.dataset)\n","  return test_loss, test_accuracy"],"metadata":{"id":"AuI22ALx3MXa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### state_dict\n","- PyTorch의 state_dict는 모델의 매개변수(parameters)와 옵티마이저(optimizer)의 상태(state)를 담고 있는 사전(dictionary) 객체\n","- state_dict는 모델을 저장하고 불러올 때 매우 유용한 포맷"],"metadata":{"id":"vUdB_KXW1KTj"}},{"cell_type":"code","source":["import time\n","import copy\n","\n","def train_baseline(model, train_loader, val_loader, optimizer, num_epochs = 30):\n","  best_acc = 0.0\n","  # wts = Weights\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","\n","  for epoch in range(1, num_epochs + 1):\n","    since = time.time()\n","    train(model, train_loader, optimizer)\n","    train_loss, train_acc = evaluate(model, train_loader)\n","    val_loss, val_acc = evaluate(model, val_loader)\n","\n","    if val_acc > best_acc:\n","      best_acc = val_acc\n","      best_model_wts = copy.deepcopy(model.state_dict())\n","\n","      time_elapsed = time.time() - since\n","      print('------------- epoch {} ---------------'.format(epoch))\n","      print('Train Loss : {:.4f}, Accuracy : {:.2f}%'.format(train_loss, train_acc))\n","      print('Val Loss : {:.4f}, Accuracy : {:.2f}%'.format(val_loss, val_acc))\n","      print('Completed in : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","  model.load_state_dict(best_model_wts)\n","  return model\n","\n","base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n","torch.save(base, 'baseline.pt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"jJoK2k9f3MZo","executionInfo":{"status":"error","timestamp":1707292691676,"user_tz":-540,"elapsed":15805,"user":{"displayName":"이병찬","userId":"10612252081270695585"}},"outputId":"814e09bb-11fc-4ded-e0cb-894f1d5f9e6f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1cbfc9611223>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baseline.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-1cbfc9611223>\u001b[0m in \u001b[0;36mtrain_baseline\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-8b0adfec2f4e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, opmtimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopmtimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### 전이학습 : 잘 학습된 모델의 가중치를 가져와서 원하는 방향으로 조금만 바꿔서 가중치를 학습시키는 것\n","- 입력단에 가까운 레이어일 수록 conventional layer, 출력단에 가까운 레이어일 수록 fully connected layer\n","- data_transforms : 이미지폴더의 함수에 옵션으로 지정\n","- Compose : 전처리 함수, 이미지 증강 설정을 한 번에 합치기\n","- 이미지 증강 : 심층 신경망에서 데이터셋을 사용할 경우 대규모 데이터셋이더라도 과적합이 발생할 수 있다. 이를 방지하고자 이미지 증강을 통해 모델의 의존도를 줄일 수 있고, 이에 따른 일반화 능력이 향상된다. 따라서 심층 신경망의 성공적인 학습을 위해 목적에 위배되지 않는다면(필수로 지켜야되는 조건들은 변경하지 않는다면) 동일한 이미지를 위치, 밝기, 색도와 같은 요소들을 무작위로 조절하면서 다양한 데이터를 만드는 것이다.\n","- https://jungnamgyu.tistory.com/32 참고"],"metadata":{"id":"Tfrq08fLwgsX"}},{"cell_type":"code","source":["data_transforms = {\n","    'train' : transforms.Compose([transforms.Resize([64, 64]),\n","        transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n","        # RandomHorizontalFlip() : 이미지 뒤집기, 좌우반전\n","        # RandomVerticalFlip() : 이미지 뒤집기, 상하반전\n","        transforms.RandomCrop(52), transforms.ToTensor(),\n","        # RandomCrop : 이미지 자르기, 전체에서 일부를 보여주는 효과\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),\n","        # Normalize : RGB 색상값의 평균값과 표준편차 지정, 색상 변경은 학습능력이 좋아진다\n","    'val' : transforms.Compose([transforms.Resize([64, 64]),\n","        transforms.RandomCrop(52), transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n","}"],"metadata":{"id":"9Ml99w90wcHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/제로베이스_코랩/splitted'\n","image_datasets = {x : ImageFolder(root=os.path.join(data_dir, x),\n","                                  transform=data_transforms[x]) for x in ['train', 'val']}\n","dataloaders = {x : torch.utils.data.DataLoader(image_datasets[x],\n","                                               batch_size = BATCH_SIZE,\n","                                               shuffle = True,\n","                                               num_workers = 4) for x in ['train', 'val']}\n","dataset_size = {x : len(image_datasets[x]) for x in ['train', 'val']}\n","\n","class_names = image_datasets['train'].classes"],"metadata":{"id":"JlOAMsTJwk-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### resnet50 학습 후 출력되는 class 숫자와 현재 모델에서 예측해야되는 숫자가 다르므로 조정 필요"],"metadata":{"id":"NuYZU8MADUgO"}},{"cell_type":"code","source":["from torchvision import models\n","# torchvision의 models를 통해 여러 모듈을 import\n","\n","resnet = models.resnet50(pretrained=True)\n","# pretrained = True 시 학습이 완료된 모듈을 가져오고, False 시 모듈의 구조만 가져오도록 설정하는 메써드\n","num_ftrs = resnet.fc.in_features\n","                    # in_features : 마지막 레이어의 채널 숫자를 의미\n","                    # 여기선 resnet50의 마지막 레이어의 채널 숫자를 의미\n","                    # 이를 num_ftrs 변수에 지정\n","resnet.fc = nn.Linear(num_ftrs, 33)\n","            # resnet50의 마지막 레이어 채널 숫자를 33개로 수정\n","resnet = resnet.to(DEVICE)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr = 0.001)\n","\n","from torch.optim import lr_scheduler\n","# lr_scheduler : epoch 마다 learning_rate를 조정\n","# 여기선 7 epoch 마다 0.1씩 learning_rate를 감소\n","# 가중치 업데이트를 크게 가져가고 learning_rate를 감소키면서 점점 작게(=세밀하게) 가져간다\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"metadata":{"id":"1DnHq6A0yiY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ct = 0\n","for child in resnet.children():\n","  # resnet는 원래 10개의 layer 존재\n","  ct += 1\n","  if ct < 6:\n","    for param in child.parameters():\n","      param.requires_grad = False\n","  # 여기선 입력에 가까운 0~5번까지 layer는 frezze(고정) 시키고(=기존에 학습이 잘되었다고 판단하여 학습시키지 않고)\n","  # 6번째 layer부터 학습을 진행시키고자 하는 설정"],"metadata":{"id":"amA6-tnb0N-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n","\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_acc = 0.0\n","\n","  for epoch in range(num_epochs):\n","    print('------------- epoch{} -------------'.format(epoch + 1))\n","    since = time.time()\n","    for phase in ['train', 'val']:\n","      if phase == 'train':\n","        model.train()\n","      else:\n","        model.eval()\n","\n","      running_loss = 0.0\n","      running_corrects = 0\n","\n","      for inputs, labels in dataloaders[phase]:\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","\n","        with torch.set_grad_enabled(phase == 'train'):\n","          # torch.set_grad_enabled(phase == 'train') : trian 폴더의 데이터라면(=train loader라면) gradient를 학습하는 것을 허락한다, 웨이트가 업데이트 되는 것을 허락한다\n","          outputs = model(inputs)\n","          _, preds = torch.max(outputs, 1)\n","          # outputs은 one_hot_encoding 형태\n","          # torch.max() 함수는 첫 번째 반환 값으로 최대 값들을, 두 번째 반환 값으로 해당 최대 값들의 인덱스를 반환\n","          # _, preds 와 같이 2개의 인자 필요\n","          loss = criterion(outputs, labels)\n","\n","          if phase == 'train' :\n","            loss.backward()\n","            optimizer.step()\n","\n","        # train이 아니라면 with 구문은 미실행\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","      if phase == 'train':\n","        scheduler.step()\n","\n","      epoch_loss = running_loss / dataset_size[phase]\n","      epoch_acc = running_corrects.double() / dataset_size[phase]\n","\n","      print('{} Loss : {:.4f} Acc : {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","      if phase == 'val' and epoch_acc > best_acc:\n","        best_acc = epoch_acc\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - since\n","    print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","  print('Best val Acc : {:.4f}'.format(best_acc))\n","\n","  model.load_state_dict(best_model_wts)\n","\n","  return model"],"metadata":{"id":"GAzaLAh20l_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_resnet50 = train_resnet(resnet, criterion, optimizer_ft, exp_lr_scheduler,\n","                              num_epochs=EPOCH)\n","torch.save(model_resnet50, 'resnet50.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gsbQOyz7jDR","outputId":"7f78df4c-73cb-4bfc-fbb0-d1decea358ee","executionInfo":{"status":"ok","timestamp":1707299006379,"user_tz":-540,"elapsed":2919413,"user":{"displayName":"이병찬","userId":"10612252081270695585"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------- epoch1 -------------\n","train Loss : 0.6069 Acc : 0.8206\n","val Loss : 0.3421 Acc : 0.9007\n","Complete in 2m 6s\n","------------- epoch2 -------------\n","train Loss : 0.2201 Acc : 0.9298\n","val Loss : 0.1981 Acc : 0.9330\n","Complete in 1m 53s\n","------------- epoch3 -------------\n","train Loss : 0.1660 Acc : 0.9463\n","val Loss : 0.2001 Acc : 0.9365\n","Complete in 1m 52s\n","------------- epoch4 -------------\n","train Loss : 0.1311 Acc : 0.9574\n","val Loss : 0.1992 Acc : 0.9259\n","Complete in 1m 54s\n","------------- epoch5 -------------\n","train Loss : 0.1178 Acc : 0.9623\n","val Loss : 0.1032 Acc : 0.9568\n","Complete in 1m 51s\n","------------- epoch6 -------------\n","train Loss : 0.0998 Acc : 0.9678\n","val Loss : 0.1330 Acc : 0.9409\n","Complete in 1m 53s\n","------------- epoch7 -------------\n","train Loss : 0.0841 Acc : 0.9721\n","val Loss : 0.1886 Acc : 0.9403\n","Complete in 1m 52s\n","------------- epoch8 -------------\n","train Loss : 0.0454 Acc : 0.9856\n","val Loss : 0.0406 Acc : 0.9872\n","Complete in 1m 53s\n","------------- epoch9 -------------\n","train Loss : 0.0275 Acc : 0.9911\n","val Loss : 0.0519 Acc : 0.9786\n","Complete in 1m 52s\n","------------- epoch10 -------------\n","train Loss : 0.0236 Acc : 0.9921\n","val Loss : 0.0528 Acc : 0.9816\n","Complete in 1m 52s\n","------------- epoch11 -------------\n","train Loss : 0.0192 Acc : 0.9935\n","val Loss : 0.0402 Acc : 0.9860\n","Complete in 1m 54s\n","------------- epoch12 -------------\n","train Loss : 0.0179 Acc : 0.9944\n","val Loss : 0.0357 Acc : 0.9872\n","Complete in 1m 52s\n","------------- epoch13 -------------\n","train Loss : 0.0178 Acc : 0.9940\n","val Loss : 0.0373 Acc : 0.9880\n","Complete in 1m 51s\n","------------- epoch14 -------------\n","train Loss : 0.0165 Acc : 0.9946\n","val Loss : 0.0279 Acc : 0.9915\n","Complete in 1m 51s\n","------------- epoch15 -------------\n","train Loss : 0.0144 Acc : 0.9949\n","val Loss : 0.0339 Acc : 0.9890\n","Complete in 1m 50s\n","------------- epoch16 -------------\n","train Loss : 0.0139 Acc : 0.9955\n","val Loss : 0.0318 Acc : 0.9915\n","Complete in 1m 54s\n","------------- epoch17 -------------\n","train Loss : 0.0124 Acc : 0.9962\n","val Loss : 0.0295 Acc : 0.9880\n","Complete in 1m 52s\n","------------- epoch18 -------------\n","train Loss : 0.0128 Acc : 0.9955\n","val Loss : 0.0300 Acc : 0.9922\n","Complete in 1m 52s\n","------------- epoch19 -------------\n","train Loss : 0.0123 Acc : 0.9960\n","val Loss : 0.0308 Acc : 0.9880\n","Complete in 1m 53s\n","------------- epoch20 -------------\n","train Loss : 0.0120 Acc : 0.9962\n","val Loss : 0.0248 Acc : 0.9934\n","Complete in 1m 53s\n","------------- epoch21 -------------\n","train Loss : 0.0119 Acc : 0.9959\n","val Loss : 0.0250 Acc : 0.9922\n","Complete in 1m 53s\n","------------- epoch22 -------------\n","train Loss : 0.0103 Acc : 0.9968\n","val Loss : 0.0271 Acc : 0.9912\n","Complete in 1m 52s\n","------------- epoch23 -------------\n","train Loss : 0.0106 Acc : 0.9967\n","val Loss : 0.0246 Acc : 0.9944\n","Complete in 1m 52s\n","------------- epoch24 -------------\n","train Loss : 0.0111 Acc : 0.9968\n","val Loss : 0.0274 Acc : 0.9927\n","Complete in 1m 54s\n","------------- epoch25 -------------\n","train Loss : 0.0121 Acc : 0.9964\n","val Loss : 0.0216 Acc : 0.9937\n","Complete in 1m 51s\n","------------- epoch26 -------------\n","train Loss : 0.0117 Acc : 0.9960\n","val Loss : 0.0228 Acc : 0.9927\n","Complete in 1m 52s\n","------------- epoch27 -------------\n","train Loss : 0.0116 Acc : 0.9965\n","val Loss : 0.0233 Acc : 0.9940\n","Complete in 1m 55s\n","------------- epoch28 -------------\n","train Loss : 0.0099 Acc : 0.9969\n","val Loss : 0.0232 Acc : 0.9949\n","Complete in 1m 54s\n","------------- epoch29 -------------\n","train Loss : 0.0111 Acc : 0.9965\n","val Loss : 0.0232 Acc : 0.9940\n","Complete in 1m 53s\n","------------- epoch30 -------------\n","train Loss : 0.0116 Acc : 0.9963\n","val Loss : 0.0230 Acc : 0.9945\n","Complete in 1m 53s\n","Best val Acc : 0.9949\n"]}]},{"cell_type":"code","source":["transform_resNet = transforms.Compose([\n","    transforms.Resize([64, 64]),\n","    transforms.RandomCrop(52),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.228, 0.224, 0.225])\n","])\n","\n","test_resNet = ImageFolder(root='/content/drive/MyDrive/제로베이스_코랩/splitted/test', transform=transform_resNet)\n","test_loader_resNet = torch.utils.data.DataLoader(test_resNet,\n","                                                 batch_size=BATCH_SIZE,\n","                                                 shuffle=True,\n","                                                 num_workers=4)"],"metadata":{"id":"jnlxc_q57-li"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet50 = torch.load('resnet50.pt')\n","resnet50.eval()\n","test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n","\n","print(\"ResNet test acc :\", test_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZOciIJW_qlG","executionInfo":{"status":"ok","timestamp":1707299804200,"user_tz":-540,"elapsed":528839,"user":{"displayName":"이병찬","userId":"10612252081270695585"}},"outputId":"953c7b36-7336-48bc-e845-525d343a5603"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet test acc : 99.29903617474027\n"]}]}]}