{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "# torchvision : 딥러닝에 사용하는 dataset을 가지는 모듈\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda(GPU) 가능 여부 및 Cuda 사용 불가 시 cpu 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device is cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print('Current cuda device is', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "# data = 60k, batch_size = 50, data_bundle(묶음) = 1.2k\n",
    "learning_rate = 0.0001\n",
    "epoch_num = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 5427013.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2648816.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1946469.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n",
      "\n",
      "number of traning data : 60000\n",
      "number of test data : 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='./data/', # 저장 경로\n",
    "    train=True, # train data 여부, False 시 test로 인식\n",
    "    download=True, # 최초 한번만 다운로드 받고 추후 False 시 지정된 경로의 data를 사용하겠다는 설정\n",
    "    transform=transforms.ToTensor() # 바로 Tensor로 바꿔주는 설정\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "print('number of traning data :', len(train_data))\n",
    "print('number of test data :', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "# .squeeze() : [1, 28, 28] 데이터를 1을 지우고 가로, 세로의 2차원의 형태로 바꿔주는 메써드\n",
    "# torchvision 모듈에서 가져온 dataset의 MNIST 데이터의 한세트는 이미 처음부터 CNN 모델을 고려하여 [1, 28, 28] 형태로 이미 바뀌어져 있다\n",
    "# keras모듈의 경우 이를 [28, 28, 1] 과 같이 수정해주었어야 했다\n",
    "plt.title('label :%s' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mini batch 구성\n",
    "### torch.utils.data.DataLoader\n",
    "- PyTorch에서 데이터를 미니배치로 나누어 학습 루프에서 사용하기 쉽게 만들어주는 유틸리티 클래스 \n",
    "- 이를 사용하면 데이터를 일괄(batch)로 가져오고, 셔플(shuffle), 병렬 로딩(parallel loading) 등의 다양한 기능을 제공 가능\n",
    "- shuffle : 데이터의 순서를 학습하는 것을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            \\ type                      \\ size\n",
      "Num of batch    \\                           \\ 1200\n",
      "first_batch     \\ <class 'list'>            \\ 2\n",
      "first_batch[0]  \\ <class 'torch.Tensor'>    \\ torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  \\ <class 'torch.Tensor'>    \\ torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print('{:15s} \\ {:<25s} \\ {}'.format('name', 'type', 'size'))\n",
    "# :15s : 15 글자칸을 확보해둬라\n",
    "# < : 왼쪽 정렬\n",
    "print('{:15s} \\ {:<25s} \\ {}'.format('Num of batch', '', len(train_loader)))\n",
    "print('{:15s} \\ {:<25s} \\ {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
    "print('{:15s} \\ {:<25s} \\ {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "                                    # first_batch[0] : 데이터\n",
    "print('{:15s} \\ {:<25s} \\ {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))\n",
    "                                    # first_batch[1] : 라벨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional.log_softmax\n",
    "\n",
    "- Softmax 함수: 주어진 벡터를 입력으로 받아, 각 요소의 지수를 계산하고, 이를 정규화하여 모든 요소의 합이 1이 되도록 만드는 함수입니다. \n",
    "- Softmax 함수는 주로 다중 클래스 분류 문제에서 출력 확률을 계산하는 데 사용됩니다.\n",
    "\n",
    "- Log-softmax 함수: Softmax 함수의 출력을 취해 로그를 취한 것입니다. 로그를 취함으로써 수치적 안정성(numerical stability)이 향상되고, \n",
    "- 학습 중에 발생할 수 있는 소수점 계산 오류를 감소시킬 수 있습니다. 수학적으로는 log(softmax(x))와 동일합니다.\n",
    "\n",
    "- 이 함수는 입력 텐서를 받아 지정된 차원(dim)을 기준으로 log-softmax를 계산합니다. 주로 손실 함수 계산이나 모델의 출력을 확률로 변환할 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, padding='same')\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding='same')\n",
    "        self.dropout = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(3136, 1000)\n",
    "        # 28 * 28 데이터가 아래와 같이 2로 풀링 되어 14 * 14로, \n",
    "        # 풀링된 14 * 14가 다시 2로 풀링되어 7 * 7로 되어\n",
    "        # 마지막 레이어의 채널 숫자인 64를 곱하게 되어 7 * 7 * 64 = 3136개의 입력값을 가지게 된다\n",
    "        # 계산이 복잡할 시 일단 코딩을 해보고 error메세지를 확인하면 값을 알려준다\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step : 1000\tLoss : 0.210\n",
      "Train Step : 2000\tLoss : 0.039\n",
      "Train Step : 3000\tLoss : 0.078\n",
      "Train Step : 4000\tLoss : 0.037\n",
      "Train Step : 5000\tLoss : 0.021\n",
      "Train Step : 6000\tLoss : 0.024\n",
      "Train Step : 7000\tLoss : 0.060\n",
      "Train Step : 8000\tLoss : 0.009\n",
      "Train Step : 9000\tLoss : 0.025\n",
      "Train Step : 10000\tLoss : 0.003\n",
      "Train Step : 11000\tLoss : 0.004\n",
      "Train Step : 12000\tLoss : 0.077\n",
      "Train Step : 13000\tLoss : 0.002\n",
      "Train Step : 14000\tLoss : 0.003\n",
      "Train Step : 15000\tLoss : 0.017\n",
      "Train Step : 16000\tLoss : 0.002\n",
      "Train Step : 17000\tLoss : 0.001\n",
      "Train Step : 18000\tLoss : 0.004\n"
     ]
    }
   ],
   "source": [
    "model.train() # 학습을 하겠다는 선언, 별도 기능은 없음\n",
    "i = 1\n",
    "for epoch in range(epoch_num):\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) #data : 하나의 batch\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Step : {}\\tLoss : {:.3f}'.format(i, loss.item()))\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set : Accurancy : 99.08%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # 테스트 하겠다는 선언, dropout 기능은 자동으로 꺼짐\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "\n",
    "print('Test set : Accurancy : {:.2f}%'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
